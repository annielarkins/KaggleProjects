{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Based off of the following tutorial: \n# https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/keras/basic_regression.ipynb#scrollTo=oRKO_x8gWKv-\n\n# Use seaborn for pairplot\n!pip install seaborn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ntry:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load in the dataset\ndataset = pd.read_csv('/kaggle/input/avocado-prices/avocado.csv')\ndataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop some columns (for now)\ndataset = dataset.drop(columns=['Unnamed: 0'], axis=1)\n\n# Drop region \ndataset = dataset.drop(columns=['region'])\n\n# Drop date \ndataset = dataset.drop(columns=['Date'])\ndataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean the data\n\n# Check for unknown vals - there aren't any!\ndataset.isna().sum()\n\n# One hot convert type\n\natype = dataset.pop('type')\ndataset['organic'] = (atype == \"organic\")*1.0\ndataset['conventional'] = (atype == \"conventional\")*1.0\n\ndataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into train and test\ntrain_dataset = dataset.sample(frac=0.8, random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect data\nsns.pairplot(train_dataset[[\"year\", \"AveragePrice\", \"Total Volume\", \"organic\"]], diag_kind=\"kde\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get overall stats\ntrain_stats = train_dataset.describe()\ntrain_stats.pop(\"AveragePrice\")\ntrain_stats = train_stats.transpose()\ntrain_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split features from labels\ntrain_labels = train_dataset.pop('AveragePrice')\ntest_labels = test_dataset.pop('AveragePrice')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize data\ndef norm(x):\n    return (x - train_stats['mean']) / train_stats['std']\n\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the model\ndef build_model():\n    model = keras.Sequential([\n        layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n        layers.Dense(32, activation='relu'),\n        layers.Dense(1)\n    ])\n    \n    optimizer = tf.keras.optimizers.RMSprop(0.001)\n    \n    model.compile(loss='mse',\n                 optimizer=optimizer,\n                 metrics=['mae', 'mse'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 1000\n\n# history = model.fit(\n#     normed_train_data, train_labels,\n#     epochs=EPOCHS, validation_split=0.2, verbose=0,\n#     callbacks=[PrintDot()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize progress\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [Price]')\n  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n           label = 'Val Error')\n  # plt.ylim([0,5])\n  plt.legend()\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error [$Price^2$]')\n  plt.plot(hist['epoch'], hist['mean_squared_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n           label = 'Val Error')\n  # plt.ylim([0,20])\n  plt.legend()\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\n\n# The patience parameter is the amount of epochs to check for improvement\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n\nplot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test on test data\nloss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n\nprint(\"Testing Set Mean Abs Error: ${:5.2f}\".format(mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict on testing set data\ntest_predictions = model.predict(normed_test_data).flatten()\n\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values [MPG]')\nplt.ylabel('Predictions [MPG]')\nplt.axis('equal')\nplt.axis('square')\nplt.xlim([0,plt.xlim()[1]])\nplt.ylim([0,plt.ylim()[1]])\n_ = plt.plot([-100, 100], [-100, 100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error Distribution\nerror = test_predictions - test_labels\nplt.hist(error, bins = 25)\nplt.xlabel(\"Prediction Error [MPG]\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}